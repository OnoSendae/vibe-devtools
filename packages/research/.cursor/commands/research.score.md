---
description: Avaliar e pontuar refer√™ncias em 5 dimens√µes, identificar top 20% para an√°lise profunda
---

## Entrada do Usu√°rio

```text
$ARGUMENTS
```

Voc√™ **DEVE** considerar a entrada do usu√°rio antes de prosseguir (se n√£o estiver vazia).

## Objetivo

Avaliar e pontuar todas as refer√™ncias encontradas na busca, aplicando scoring multi-dimensional (0-10) em credibilidade, relev√¢ncia, rec√™ncia, profundidade e autoridade. Este command analisa cada refer√™ncia, extrai fatores de qualidade do conte√∫do de entrada, calcula score ponderado, e identifica o top 20% para an√°lise profunda subsequente.

O output √© metadados atualizados com scores para todas as refer√™ncias, estat√≠sticas de distribui√ß√£o, e lista priorizada para an√°lise. **PAUSA** ap√≥s scoring para aprova√ß√£o humana (configur√°vel), permitindo ajustes antes de investir tempo em an√°lise profunda.

**Quando usar**: Logo ap√≥s `/research.search`, quando refer√™ncias foram coletadas e precisam ser priorizadas.

**Pr√©-requisitos**: 
- Research com status "searching" ou "initialized"
- Refer√™ncias encontradas (`metadata.references` populado)

## Descoberta & Valida√ß√£o

Antes de pontuar, voc√™ **DEVE** validar:

### Informa√ß√µes Obrigat√≥rias

1. **Research ID**: Qual pesquisa pontuar?
   - Se fornecido em $ARGUMENTS: Usar
   - Se n√£o fornecido: ERRO

2. **Refer√™ncias Existem**: H√° refer√™ncias para pontuar?
   - Validar que `metadata.references` n√£o est√° vazio
   - Se vazio: ERRO - "Nenhuma refer√™ncia para pontuar, execute /research.search primeiro"

### Prefer√™ncias Opcionais

1. **Top Percentage**: Qual % analisar profundamente?
   - Padr√£o: 20% (top 20%)
   - Override: `--top-percent N` em $ARGUMENTS
   - Min: 5%, Max: 50%

2. **Skip Pause**: Pular pausa de aprova√ß√£o?
   - Padr√£o: Pausar ap√≥s scoring (configura√ß√£o do metadata)
   - Override: `--no-pause` em $ARGUMENTS
   - Use apenas se confia 100% no scoring autom√°tico

3. **Score Threshold**: Score m√≠nimo para an√°lise?
   - Padr√£o: Usar top percentage
   - Override: `--min-score N` (0-10)
   - Se fornecido, sobrescreve top percentage

## Fluxo de Execu√ß√£o

### Fase 1: Carregar e Validar

1. **Parsear Argumentos**:
   - Extrair research_id (primeiro argumento)
   - Extrair flags: `--top-percent`, `--no-pause`, `--min-score`
   - Validar argumentos

2. **Carregar Metadados**:
   - Path: `./memory/[RESEARCH_ID]/metadata.json`
   - Parse JSON e validar
   - Extrair:
     * `objective` (para avaliar relev√¢ncia)
     * `references` (array para pontuar)
     * `configuration.topPercentageForAnalysis`
     * `configuration.pauseAfterScoring`
     * `inputSources[].extractedKeywords`

3. **Validar Pre-requisitos**:
   - Status deve ser "searching" ou "initialized"
   - Array `references` n√£o vazio (min 1 refer√™ncia)
   - Se falhar: ERRO com mensagem clara

### Fase 2: Extrair Fatores de Scoring do Objetivo

1. **Analisar Objetivo da Pesquisa**:
   - Extrair palavras-chave cr√≠ticas de `objective.question`
   - Extrair contexto de `objective.scope`
   - Identificar tecnologias, metodologias mencionadas
   - Identificar restri√ß√µes temporais (ex: "√∫ltimos 2 anos")

2. **Criar Perfil de Relev√¢ncia**:
   ```javascript
   const relevanceProfile = {
     keywords: ['keyword1', 'keyword2', ...],  // Must-have
     technologies: ['tech1', 'tech2'],          // Tecnologias espec√≠ficas
     domains: ['domain1', 'domain2'],           // Dom√≠nios desejados
     temporalFocus: 'recent|current|historical', // Foco temporal
     contentTypes: ['tutorial', 'documentation', 'academic'], // Tipos preferidos
     excludePatterns: ['pattern1']              // Padr√µes a evitar
   };
   ```

3. **Definir Pesos de Dimens√µes**:
   ```javascript
   const weights = {
     credibility: 0.25,  // 25%
     relevance: 0.30,    // 30% (mais importante)
     recency: 0.15,      // 15%
     depth: 0.20,        // 20%
     authority: 0.10     // 10%
   };
   ```

### Fase 3: Pontuar Cada Refer√™ncia

Para cada refer√™ncia em `metadata.references`:

#### 3.1 Avaliar Credibilidade (0-10)

**Fatores**:
- **Dom√≠nio confi√°vel**: `.edu`, `.gov`, docs oficiais ‚Üí 8-10
- **Dom√≠nio conhecido**: GitHub, Medium, Dev.to ‚Üí 6-8
- **Dom√≠nio desconhecido**: ‚Üí 3-6
- **Dom√≠nios suspeitos**: Spam patterns ‚Üí 0-2

**Verifica√ß√µes**:
```javascript
let credibilityScore = 5; // Base

if (url.includes('.edu') || url.includes('.gov')) {
  credibilityScore += 3;
} else if (isOfficialDocs(url)) {
  credibilityScore += 4;
} else if (isKnownPlatform(url)) {  // GitHub, StackOverflow, etc
  credibilityScore += 2;
}

if (hasSSL(url)) credibilityScore += 1;
if (isDomainReputated(url)) credibilityScore += 1;

credibilityScore = Math.min(10, credibilityScore);
```

**Reasoning**: Documentar por que este score

#### 3.2 Avaliar Relev√¢ncia (0-10)

**Fatores**:
- **Keywords match**: Quantos keywords do objetivo aparecem?
- **Title alignment**: T√≠tulo alinhado com pergunta?
- **Snippet quality**: Snippet menciona conceitos-chave?
- **Category match**: Categoria alinha com tipo buscado?

**C√°lculo**:
```javascript
let relevanceScore = 0;

// Keywords no t√≠tulo e snippet
const keywordMatches = countKeywordMatches(
  title + ' ' + snippet,
  relevanceProfile.keywords
);
relevanceScore += Math.min(5, keywordMatches);

// Tecnologias mencionadas
const techMatches = countMatches(
  title + ' ' + snippet,
  relevanceProfile.technologies
);
relevanceScore += Math.min(3, techMatches);

// Alinhamento sem√¢ntico
const semanticAlignment = assessSemanticAlignment(
  title + ' ' + snippet,
  objective.question
);
relevanceScore += semanticAlignment; // 0-2

relevanceScore = Math.min(10, relevanceScore);
```

**Reasoning**: Documentar keywords encontrados e alinhamento

#### 3.3 Avaliar Rec√™ncia (0-10)

**Fatores**:
- **Data de publica√ß√£o**: Se dispon√≠vel no snippet/URL
- **Dom√≠nio atualizado**: Sites ativamente mantidos
- **Conte√∫do evergreen vs temporal**: Alguns t√≥picos n√£o exigem rec√™ncia

**Heur√≠sticas**:
```javascript
let recencyScore = 5; // Base (assume moderadamente recente)

// Tentar extrair ano de URL ou snippet
const year = extractYear(url, snippet);

if (year) {
  const currentYear = 2025;
  const age = currentYear - year;
  
  if (age === 0) recencyScore = 10;      // Este ano
  else if (age === 1) recencyScore = 9;  // Ano passado
  else if (age === 2) recencyScore = 7;  // 2 anos
  else if (age <= 5) recencyScore = 5;   // 3-5 anos
  else if (age <= 10) recencyScore = 3;  // 6-10 anos
  else recencyScore = 1;                 // >10 anos
}

// Ajustar se t√≥pico √© evergreen
if (isEvergreenTopic(objective)) {
  recencyScore += 2; // Menos penalidade por idade
}

recencyScore = Math.min(10, recencyScore);
```

**Reasoning**: Documentar ano e l√≥gica

#### 3.4 Avaliar Profundidade (0-10)

**Fatores**:
- **Snippet length**: Snippets longos ‚Üí mais conte√∫do
- **Keywords diversity**: Mais keywords ‚Üí mais completo
- **Content indicators**: "tutorial", "guide", "comprehensive" ‚Üí profundo
- **Domain patterns**: Documenta√ß√£o oficial ‚Üí geralmente profunda

**C√°lculo**:
```javascript
let depthScore = 3; // Base (assume b√°sico)

// Snippet length
if (snippet.length > 200) depthScore += 2;
else if (snippet.length > 100) depthScore += 1;

// Indicadores de profundidade no t√≠tulo/snippet
const depthIndicators = [
  'tutorial', 'guide', 'comprehensive', 'complete',
  'in-depth', 'detailed', 'deep dive', 'advanced'
];
const hasIndicators = depthIndicators.some(ind => 
  (title + snippet).toLowerCase().includes(ind)
);
if (hasIndicators) depthScore += 3;

// Tipo de conte√∫do
if (categories.includes('documentation')) depthScore += 2;
if (categories.includes('academic')) depthScore += 3;
if (categories.includes('tutorial')) depthScore += 2;

depthScore = Math.min(10, depthScore);
```

**Reasoning**: Documentar indicadores encontrados

#### 3.5 Avaliar Autoridade (0-10)

**Fatores**:
- **Autor conhecido**: Experts da √°rea
- **Organiza√ß√£o reputada**: Empresas/universidades conhecidas
- **Dom√≠nio autoritativo**: Sites refer√™ncia da √°rea
- **Citations/popularity**: Se detect√°vel (ex: GitHub stars)

**C√°lculo**:
```javascript
let authorityScore = 5; // Base

// Organiza√ß√µes conhecidas
const authoritativeOrgs = [
  'mozilla.org', 'w3.org', 'github.com', 'reactnative.dev',
  'microsoft.com', 'google.com', 'aws.amazon.com'
];
if (authoritativeOrgs.some(org => url.includes(org))) {
  authorityScore += 3;
}

// Academic
if (url.includes('.edu') || categories.includes('academic')) {
  authorityScore += 2;
}

// Padr√µes de autoridade no t√≠tulo
const authorityPatterns = ['official', 'documentation', 'reference'];
if (authorityPatterns.some(p => title.toLowerCase().includes(p))) {
  authorityScore += 2;
}

authorityScore = Math.min(10, authorityScore);
```

**Reasoning**: Documentar fonte de autoridade

#### 3.6 Calcular Score Total Ponderado

```javascript
const totalScore = (
  (credibilityScore * weights.credibility) +
  (relevanceScore * weights.relevance) +
  (recencyScore * weights.recency) +
  (depthScore * weights.depth) +
  (authorityScore * weights.authority)
);

// Arredondar para 1 casa decimal
const finalScore = Math.round(totalScore * 10) / 10;
```

#### 3.7 Atualizar Refer√™ncia com Scoring

```javascript
reference.scoring = {
  totalScore: finalScore,
  dimensions: {
    credibility: credibilityScore,
    relevance: relevanceScore,
    recency: recencyScore,
    depth: depthScore,
    authority: authorityScore
  },
  reasoning: `
    Credibility (${credibilityScore}/10): [Reasoning]
    Relevance (${relevanceScore}/10): [Reasoning]
    Recency (${recencyScore}/10): [Reasoning]
    Depth (${depthScore}/10): [Reasoning]
    Authority (${authorityScore}/10): [Reasoning]
  `,
  scoredAt: new Date().toISOString()
};
```

### Fase 4: Calcular Estat√≠sticas

1. **Ordenar Refer√™ncias por Score**:
   ```javascript
   const sortedRefs = metadata.references.sort(
     (a, b) => b.scoring.totalScore - a.scoring.totalScore
   );
   ```

2. **Calcular Distribui√ß√£o**:
   ```javascript
   const stats = {
     totalReferences: sortedRefs.length,
     scoredReferences: sortedRefs.length,
     averageScore: average(sortedRefs.map(r => r.scoring.totalScore)),
     medianScore: median(sortedRefs.map(r => r.scoring.totalScore)),
     referencesByScore: {
       high: sortedRefs.filter(r => r.scoring.totalScore >= 7.0).length,
       medium: sortedRefs.filter(r => r.scoring.totalScore >= 4.0 && r.scoring.totalScore < 7.0).length,
       low: sortedRefs.filter(r => r.scoring.totalScore < 4.0).length
     }
   };
   ```

3. **Identificar Top Percentage**:
   ```javascript
   const topPercent = configuration.topPercentageForAnalysis;
   const topCount = Math.ceil(sortedRefs.length * topPercent);
   
   const topRefs = sortedRefs.slice(0, topCount);
   const thresholdScore = topRefs[topRefs.length - 1].scoring.totalScore;
   
   stats.topScoredCount = topCount;
   stats.scoreThreshold = thresholdScore;
   ```

### Fase 5: Gerar Relat√≥rio de Scoring

1. **Criar Relat√≥rio Detalhado**:
   ```markdown
   ## üìä Scoring Completo
   
   **Research**: [RESEARCH_NAME]
   **Research ID**: [RESEARCH_ID]
   **Scored at**: [TIMESTAMP]
   
   ### Estat√≠sticas
   
   **Total Scored**: [N] refer√™ncias
   **Average Score**: [AVG]/10
   **Median Score**: [MEDIAN]/10
   
   **Distribui√ß√£o**:
   - High (‚â•7.0): [N] ([X]%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
   - Medium (4.0-6.9): [N] ([X]%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
   - Low (<4.0): [N] ([X]%)  ‚ñà‚ñà‚ñà‚ñà
   
   ### Top [X]% para An√°lise Profunda
   
   **Count**: [N] refer√™ncias
   **Threshold Score**: ‚â• [THRESHOLD]/10
   
   #### Top 10 Refer√™ncias
   
   1. **[TITLE]** - Score: [SCORE]/10
      - URL: [URL]
      - Reasoning: [BRIEF_REASONING]
      - Dimensions: C:[X] R:[X] Rec:[X] D:[X] A:[X]
   
   2. **[TITLE]** - Score: [SCORE]/10
      ...
   
   ### Dimens√µes - M√©dias
   
   | Dimension | Avg Score | Std Dev |
   |-----------|-----------|---------|
   | Credibility | [AVG]/10 | [STD] |
   | Relevance | [AVG]/10 | [STD] |
   | Recency | [AVG]/10 | [STD] |
   | Depth | [AVG]/10 | [STD] |
   | Authority | [AVG]/10 | [STD] |
   
   ### Categorias no Top [X]%
   
   | Category | Count | Percentage |
   |----------|-------|------------|
   | documentation | [N] | [X]% |
   | tutorial | [N] | [X]% |
   | academic | [N] | [X]% |
   | blog | [N] | [X]% |
   | other | [N] | [X]% |
   ```

2. **Salvar Relat√≥rio**:
   - Path: `./memory/[RESEARCH_ID]/scoring-report.md`
   - Markdown format

### Fase 6: Pausa para Aprova√ß√£o (Condicional)

**SE `configuration.pauseAfterScoring == true` E `--no-pause` N√ÉO fornecido**:

1. **Apresentar Resumo ao Usu√°rio**:
   ```markdown
   ‚è∏Ô∏è APROVA√á√ÉO NECESS√ÅRIA
   
   **[N] refer√™ncias pontuadas**
   **Top [X]% identificado**: [N] refer√™ncias (score ‚â• [THRESHOLD])
   
   ### Top 5 Refer√™ncias Selecionadas:
   
   1. [TITLE] - [SCORE]/10
   2. [TITLE] - [SCORE]/10
   3. [TITLE] - [SCORE]/10
   4. [TITLE] - [SCORE]/10
   5. [TITLE] - [SCORE]/10
   
   ### A√ß√µes Dispon√≠veis:
   
   1. **APPROVE**: Prosseguir com an√°lise profunda destas [N] refer√™ncias
   2. **ADJUST**: Ajustar threshold ou percentage
      - Op√ß√µes: `--top-percent N` ou `--min-score N`
   3. **REVIEW**: Revisar lista completa antes de decidir
      - Ver: `./memory/[ID]/scoring-report.md`
   4. **MANUAL**: Marcar manualmente quais analisar
   
   **Escolha [1-4]**: _
   ```

2. **Processar Escolha**:
   - **APPROVE**: Atualizar metadata e prosseguir
   - **ADJUST**: Re-calcular top refs com novos par√¢metros
   - **REVIEW**: Mostrar relat√≥rio completo e aguardar
   - **MANUAL**: Permitir sele√ß√£o manual de IDs

**SE `pauseAfterScoring == false` OU `--no-pause` fornecido**:
- Pular aprova√ß√£o, usar top percentage automaticamente

### Fase 7: Atualizar Metadados

1. **Atualizar Campos**:
   ```json
   {
     "status": "scored",
     "updated": "[TIMESTAMP]",
     "references": [
       // Array com todas refs + scoring
     ],
     "statistics": {
       "totalReferences": 87,
       "scoredReferences": 87,
       "analyzedReferences": 0,
       "averageScore": 6.3,
       "topScoredCount": 17,
       "scoreThreshold": 7.2,
       "referencesByScore": {
         "high": 24,
         "medium": 51,
         "low": 12
       }
     },
     "notes": [
       ...existing,
       {
         "timestamp": "[TIMESTAMP]",
         "author": "ai",
         "content": "Scoring completed: 87 refs scored, top 17 (20%) identified for analysis"
       }
     ]
   }
   ```

2. **Salvar Metadados**:
   - Pretty-print JSON
   - Backup anterior antes de salvar

### Fase 8: Reportar e Preparar Pr√≥ximo Passo

1. **Reportar Conclus√£o**:
   ```markdown
   ‚úÖ Scoring Conclu√≠do!
   
   **Research**: [RESEARCH_NAME]
   
   ## Resultados
   
   **Total Scored**: [N] refer√™ncias
   **Average Score**: [AVG]/10
   
   **Top [X]% Selecionado**: [N] refer√™ncias
   **Score Threshold**: ‚â• [THRESHOLD]/10
   
   ## Distribui√ß√£o
   
   - High (‚â•7.0): [N] ([X]%)
   - Medium (4.0-6.9): [N] ([X]%)
   - Low (<4.0): [N] ([X]%)
   
   ## Pr√≥ximos Passos
   
   ### Passo 1: An√°lise Profunda
   ```
   /research.analyze [RESEARCH_ID]
   ```
   
   Analisar em profundidade as [N] refer√™ncias top-scored, gerando relat√≥rios detalhados para cada uma.
   
   **Estimativa de tempo**: ~[X] minutos ([N] refs √ó 2-3 min/ref)
   
   **S√≠nteses incrementais**: A cada 10 refer√™ncias analisadas
   
   ---
   
   **Relat√≥rio completo**: `./memory/[ID]/scoring-report.md`
   
   **Quer iniciar an√°lise profunda automaticamente?** (sim/n√£o)
   ```

2. **Perguntar Execu√ß√£o Autom√°tica**:
   - "Quer que eu execute /research.analyze agora?"
   - SE sim: Chamar research.analyze
   - SE n√£o: Apenas reportar

## Princ√≠pios Operacionais

### Padr√µes de Qualidade

- **Objetividade**: Scoring DEVE ser baseado em crit√©rios claros e documentados
- **Transpar√™ncia**: Reasoning de cada score DEVE ser documentado
- **Consist√™ncia**: Mesmos crit√©rios aplicados a todas refer√™ncias
- **Rastreabilidade**: Scores e reasoning DEVEM ser salvos em metadata
- **Valida√ß√£o Humana**: SEMPRE pausar para aprova√ß√£o (a menos que explicitamente desabilitado)

### Tratamento de Erros

- **Se research_id n√£o fornecido**: ERRO
- **Se research n√£o existe**: ERRO
- **Se nenhuma refer√™ncia**: ERRO - "Execute /research.search primeiro"
- **Se refer√™ncias j√° pontuadas**: AVISAR - "Re-scoring?" (sim/n√£o)
- **Se erro ao calcular score**: Log warning, usar score padr√£o 5.0
- **Se metadata corrompido**: ERRO - Sugerir backup/restaura√ß√£o

### Restri√ß√µes

- SEMPRE pontuar TODAS as refer√™ncias (n√£o pular)
- SEMPRE calcular todas 5 dimens√µes
- SEMPRE calcular score ponderado
- SEMPRE documentar reasoning
- SEMPRE ordenar por score (maior ‚Üí menor)
- SEMPRE calcular estat√≠sticas completas
- SEMPRE identificar top percentage
- SEMPRE pausar para aprova√ß√£o (a menos que --no-pause)
- SEMPRE salvar scoring-report.md
- NUNCA sobrescrever scores sem confirma√ß√£o (se re-scoring)
- NUNCA usar scores arbitr√°rios sem reasoning

## Exemplos

### Exemplo 1: Scoring Bem-Sucedido

```
Input: /research.score rn-biometric-auth

Output:
‚úÖ Scoring Conclu√≠do!

**Research**: Autentica√ß√£o Biom√©trica em React Native

## Resultados

**Total Scored**: 87 refer√™ncias
**Average Score**: 6.3/10

**Top 20% Selecionado**: 17 refer√™ncias
**Score Threshold**: ‚â• 7.2/10

## Distribui√ß√£o

- High (‚â•7.0): 24 (28%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
- Medium (4.0-6.9): 51 (59%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
- Low (<4.0): 12 (14%)  ‚ñà‚ñà‚ñà‚ñà

## Top 5 Refer√™ncias

1. **React Native Biometrics Official Docs** - 9.4/10
   - Credibility: 10, Relevance: 10, Recency: 9, Depth: 9, Authority: 9

2. **Implementing Face ID Tutorial** - 8.9/10
   - Credibility: 8, Relevance: 10, Recency: 10, Depth: 8, Authority: 8

...

Pr√≥ximo: /research.analyze rn-biometric-auth

Quer iniciar an√°lise profunda automaticamente? _
```

### Exemplo 2: Ajuste de Threshold

```
Input: /research.score api-perf-optimization --min-score 8.0

Output:
‚úÖ Scoring Conclu√≠do!

**Total Scored**: 142 refer√™ncias
**Average Score**: 5.9/10

**Score Threshold Customizado**: ‚â• 8.0/10
**Selecionado**: 12 refer√™ncias (8.5% do total)

‚ö†Ô∏è Threshold alto pode limitar an√°lise.
Recomenda√ß√£o: Considere --min-score 7.0 para 25 refer√™ncias (18%)

Prosseguir com threshold 8.0? (sim/ajustar)
```

## Integra√ß√£o

### Posi√ß√£o no Workflow

**Precedido por**: `/research.search` (busca de refer√™ncias)

**Seguido por**: `/research.analyze` (an√°lise profunda)

### Depend√™ncias

**Commands Obrigat√≥rios**: 
- `/research.search` (deve ter refer√™ncias)

**Commands Opcionais**: Nenhum

### Fluxo de Dados

```
/research.search
       ‚Üì (produz: Refer√™ncias)
  /research.score ‚Üê VOC√ä EST√Å AQUI
       ‚Üì (produz: Refer√™ncias pontuadas + Top list)
  /research.analyze
```

## Contexto

$ARGUMENTS

## Checklist de Qualidade

Antes de considerar scoring completo:

### Execu√ß√£o
- [ ] Research ID validado
- [ ] Metadata carregado
- [ ] Todas refer√™ncias pontuadas (100%)
- [ ] 5 dimens√µes calculadas para cada
- [ ] Scores ponderados calculados
- [ ] Reasoning documentado

### Resultados
- [ ] Refer√™ncias ordenadas por score
- [ ] Estat√≠sticas calculadas (avg, median, distribui√ß√£o)
- [ ] Top percentage identificado
- [ ] Threshold definido
- [ ] Relat√≥rio gerado e salvo

### Aprova√ß√£o
- [ ] Pausa executada (se configurado)
- [ ] Usu√°rio aprovou OU --no-pause usado
- [ ] Ajustes aplicados (se solicitados)

### Metadados
- [ ] Status atualizado para "scored"
- [ ] statistics completo
- [ ] Scores salvos em metadata
- [ ] Note adicionada

